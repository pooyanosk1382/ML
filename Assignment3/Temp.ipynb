{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-05T20:17:55.543375800Z",
     "start_time": "2024-06-05T20:17:55.532192Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, ExtraTreesClassifier\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "data": {
      "text/plain": "                                               Sentence Emotion\n0     کی گفته مرد گریه نمیکنه!؟!؟ سیلم امشب سیل #اصفهان     SAD\n1     عکسی که چند روز پیش گذاشته بودم این فیلم الانش...   OTHER\n2     تنهاییم شبیه تنهاییه ظهرای بچگیم شده وقتی که ه...     SAD\n3              خوبه تمام قسمت‌های گوشی رو محافظت می‌کنه   HAPPY\n4     این خاک مال مردمان است نه حاکمان #ایران #مهسا_...   ANGRY\n...                                                 ...     ...\n4919  من از بو و ماندگاریش راضی بودم ، قیمتش هم‌ مناسبه   HAPPY\n4920  گاز نداریم آب نداریم برق نداریم نت نداریم پول ...     SAD\n4921  یکی بهم گفت برنو چرا عاشق نمیشی گفتم ما پول عا...     SAD\n4922  زیادی داریم به قضیه ی گاز میپردازیم فقط فراخوا...   OTHER\n4923  سلام. خیلی مواظبت کنید این ویروس کوفتی رو‌ نگی...     SAD\n\n[4924 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sentence</th>\n      <th>Emotion</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>کی گفته مرد گریه نمیکنه!؟!؟ سیلم امشب سیل #اصفهان</td>\n      <td>SAD</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>عکسی که چند روز پیش گذاشته بودم این فیلم الانش...</td>\n      <td>OTHER</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>تنهاییم شبیه تنهاییه ظهرای بچگیم شده وقتی که ه...</td>\n      <td>SAD</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>خوبه تمام قسمت‌های گوشی رو محافظت می‌کنه</td>\n      <td>HAPPY</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>این خاک مال مردمان است نه حاکمان #ایران #مهسا_...</td>\n      <td>ANGRY</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4919</th>\n      <td>من از بو و ماندگاریش راضی بودم ، قیمتش هم‌ مناسبه</td>\n      <td>HAPPY</td>\n    </tr>\n    <tr>\n      <th>4920</th>\n      <td>گاز نداریم آب نداریم برق نداریم نت نداریم پول ...</td>\n      <td>SAD</td>\n    </tr>\n    <tr>\n      <th>4921</th>\n      <td>یکی بهم گفت برنو چرا عاشق نمیشی گفتم ما پول عا...</td>\n      <td>SAD</td>\n    </tr>\n    <tr>\n      <th>4922</th>\n      <td>زیادی داریم به قضیه ی گاز میپردازیم فقط فراخوا...</td>\n      <td>OTHER</td>\n    </tr>\n    <tr>\n      <th>4923</th>\n      <td>سلام. خیلی مواظبت کنید این ویروس کوفتی رو‌ نگی...</td>\n      <td>SAD</td>\n    </tr>\n  </tbody>\n</table>\n<p>4924 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train_data.csv')\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T20:17:55.974744900Z",
     "start_time": "2024-06-05T20:17:55.951860400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "data": {
      "text/plain": "(4924, 2)"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T20:17:57.255827500Z",
     "start_time": "2024-06-05T20:17:57.240068700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "data": {
      "text/plain": "Sentence    0\nEmotion     0\ndtype: int64"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T20:17:58.069468600Z",
     "start_time": "2024-06-05T20:17:58.037912100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "data": {
      "text/plain": "<AxesSubplot: >"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_df = df.Emotion.value_counts()\n",
    "plot_df.plot(kind=\"bar\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T20:17:58.858340400Z",
     "start_time": "2024-06-05T20:17:58.735979400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210\n",
      "{'z', 'ᴇ', 'ش', 'آ', 'r', 'w', '‘', '6', 'د', 'ی', 'ل', '(', '.', ' ', 'B', '؟', '9', 'ɴ', '}', 'ح', 'U', '٢', 'ج', '♀', 'ʏ', '7', 's', 'ذ', 'ظ', 'Y', ',', ']', 'ء', '۸', '۰', '۳', 'T', 'D', '٬', 'ۀ', '،', 'M', '»', '✍', '0', '۴', 'y', 'ى', 'ٔ', '؛', 'E', '\\u2069', 'ک', 'ت', '\\u2066', 'ط', 'ز', '☹', '&', '2', 'ّ', 'ᴛ', '⭕', '_', ':', 'ᴏ', 'l', '⁉', '°', '=', '|', '%', '‐', 'Q', 'q', 'م', '/', 'َ', '-', '۹', 'ە', '’', '۵', '”', '⭐', 'x', '¹', '\\u200d', '?', 'ي', '۱', 'ے', 'ا', '☄', '\\n', '⛓', 'س', '٦', 'S', '٫', 'ق', '5', 'ټ', 'O', 'ژ', '⃟', 'G', 'J', '٪', '❤', '۲', 'm', 'W', 'گ', '+', 'P', 'ص', '♥', 'c', 'خ', 'ر', 'ه', 'a', '3', '۔', '!', '۶', '٠', '☝', 'f', '✅', 'C', '✨', 't', 'ب', '*', '⊰', '۷', '️', '☺', '٣', 'h', '\\u200c', 'چ', 'ن', 'I', '⚘', '#', '☠', '²', 'ث', ')', 'پ', '☘', '4', '١', 'K', 'و', 'i', '«', 'e', '1', 'ُ', 'o', 'ْ', 'ؤ', 'ف', 'g', 'n', 'u', '⚽', 'ہ', 'R', 'v', 'ض', 'F', '✌', 'A', 'ك', 'j', '❄', '8', '^', 'ھ', 'غ', 'L', 'ِ', 'ة', 'k', 'H', 'ً', ';', 'b', '♂', 'p', '[', 'ئ', '•', '…', '“', 'Z', 'd', '\\u2067', 'V', 'أ', '✋', '~', 'ـ', 'ع', 'N'}\n"
     ]
    }
   ],
   "source": [
    "uniqueChars = set(''.join(df['Sentence']))\n",
    "print(len(uniqueChars))\n",
    "print(uniqueChars)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T20:18:00.222060400Z",
     "start_time": "2024-06-05T20:18:00.202476300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "def normalize_persian(text):\n",
    "    # Define a function to normalize Persian characters\n",
    "    persian_digits = '۰۱۲۳۴۵۶۷۸۹٦'\n",
    "    english_digits = '01234567896'\n",
    "    yeh_characters = ['ی', 'ي', 'ے', 'ئ', 'ى']\n",
    "\n",
    "    text = text.translate(str.maketrans(persian_digits, english_digits))\n",
    "    for char in yeh_characters:\n",
    "        text = text.replace(char, 'ی')\n",
    "\n",
    "    return text"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T20:18:01.015078700Z",
     "start_time": "2024-06-05T20:18:01.000975Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # Normalize Persian characters\n",
    "    text = normalize_persian(text)\n",
    "\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Add more preprocessing steps as needed\n",
    "\n",
    "    return text"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T20:18:01.550999400Z",
     "start_time": "2024-06-05T20:18:01.550474700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210\n",
      "{'z', 'ᴇ', 'ش', 'آ', 'r', 'w', '‘', '6', 'د', 'ی', 'ل', '(', '.', ' ', 'B', '؟', '9', 'ɴ', '}', 'ح', 'U', '٢', 'ج', '♀', 'ʏ', '7', 's', 'ذ', 'ظ', 'Y', ',', ']', 'ء', '۸', '۰', '۳', 'T', 'D', '٬', 'ۀ', '،', 'M', '»', '✍', '0', '۴', 'y', 'ى', 'ٔ', '؛', 'E', '\\u2069', 'ک', 'ت', '\\u2066', 'ط', 'ز', '☹', '&', '2', 'ّ', 'ᴛ', '⭕', '_', ':', 'ᴏ', 'l', '⁉', '°', '=', '|', '%', '‐', 'Q', 'q', 'م', '/', 'َ', '-', '۹', 'ە', '’', '۵', '”', '⭐', 'x', '¹', '\\u200d', '?', 'ي', '۱', 'ے', 'ا', '☄', '\\n', '⛓', 'س', '٦', 'S', '٫', 'ق', '5', 'ټ', 'O', 'ژ', '⃟', 'G', 'J', '٪', '❤', '۲', 'm', 'W', 'گ', '+', 'P', 'ص', '♥', 'c', 'خ', 'ر', 'ه', 'a', '3', '۔', '!', '۶', '٠', '☝', 'f', '✅', 'C', '✨', 't', 'ب', '*', '⊰', '۷', '️', '☺', '٣', 'h', '\\u200c', 'چ', 'ن', 'I', '⚘', '#', '☠', '²', 'ث', ')', 'پ', '☘', '4', '١', 'K', 'و', 'i', '«', 'e', '1', 'ُ', 'o', 'ْ', 'ؤ', 'ف', 'g', 'n', 'u', '⚽', 'ہ', 'R', 'v', 'ض', 'F', '✌', 'A', 'ك', 'j', '❄', '8', '^', 'ھ', 'غ', 'L', 'ِ', 'ة', 'k', 'H', 'ً', ';', 'b', '♂', 'p', '[', 'ئ', '•', '…', '“', 'Z', 'd', '\\u2067', 'V', 'أ', '✋', '~', 'ـ', 'ع', 'N'}\n"
     ]
    }
   ],
   "source": [
    "uniqueChars = set(''.join(df['Sentence']))\n",
    "print(len(uniqueChars))\n",
    "print(uniqueChars)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T20:18:02.107282300Z",
     "start_time": "2024-06-05T20:18:02.103399100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4924, 10159)\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the text data\n",
    "df['Sentence'] = df['Sentence'].apply(preprocess_text)\n",
    "encoder = OrdinalEncoder()\n",
    "# Fit and transform the 'emotion' column\n",
    "df['emotion'] = encoder.fit_transform(df[['Emotion']])\n",
    "\n",
    "# Extract features using TF-IDF\n",
    "tfidf = TfidfVectorizer()\n",
    "X_tfidf = tfidf.fit_transform(df['Sentence'])\n",
    "print(X_tfidf.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T20:18:03.657056200Z",
     "start_time": "2024-06-05T20:18:03.553506300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4924, 30)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=30, random_state=42)\n",
    "X_tfidf = pca.fit_transform(X_tfidf)\n",
    "print(X_tfidf.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T19:33:03.039434700Z",
     "start_time": "2024-06-05T19:33:02.890576100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "param_grids = {\n",
    "    'Decision Tree': {'criterion': ['gini', 'entropy'], 'max_depth': [5, 10, 15, None]},\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T20:18:12.326362200Z",
     "start_time": "2024-06-05T20:18:12.316476700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing Decision Tree model...\n",
      "Decision Tree - Best Hyperparameters: {'criterion': 'gini', 'max_depth': None}\n"
     ]
    }
   ],
   "source": [
    "for model_name, model_class in [\n",
    "    ('Decision Tree', DecisionTreeClassifier),\n",
    "]:\n",
    "    print(f'Optimizing {model_name} model...')\n",
    "    model = model_class()\n",
    "    grid_search = GridSearchCV(model, param_grid=param_grids[model_name], cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42), scoring=['accuracy', 'f1_weighted'], refit='accuracy')\n",
    "    grid_search.fit(X_tfidf, df['emotion'])\n",
    "\n",
    "    #print(f'{model_name} - Best Accuracy: {grid_search.best_score_[\"accuracy\"]:.2f}')\n",
    "    #print(f'{model_name} - Best F1-score: {grid_search.best_score_[\"f1_weighted\"]:.2f}')\n",
    "    print(f'{model_name} - Best Hyperparameters: {grid_search.best_params_}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T20:18:25.836129100Z",
     "start_time": "2024-06-05T20:18:12.765810600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: 0.47\n",
      "Average F1-score: 0.46\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "model = DecisionTreeClassifier(criterion='gini', max_depth=15)\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracy_scores = []\n",
    "f1_scores = []\n",
    "\n",
    "for train_index, test_index in skf.split(X_tfidf, df['emotion']):\n",
    "    X_train_tfidf, X_test_tfidf = X_tfidf[train_index], X_tfidf[test_index]\n",
    "    y_train, y_test = df['emotion'].iloc[train_index], df['emotion'].iloc[test_index]\n",
    "\n",
    "    model.fit(X_train_tfidf, y_train)\n",
    "    y_pred = model.predict(X_test_tfidf)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "    accuracy_scores.append(accuracy)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "print(f'Average Accuracy: {sum(accuracy_scores) / len(accuracy_scores):.2f}')\n",
    "print(f'Average F1-score: {sum(f1_scores) / len(f1_scores):.2f}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T20:18:52.034908800Z",
     "start_time": "2024-06-05T20:18:50.804336100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "param_grids = {\n",
    "    'Random Forest': {'n_estimators': [50, 100, 150], 'max_depth': [5, 10, 15, None]},\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T20:23:01.196760700Z",
     "start_time": "2024-06-05T20:23:01.193751500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing Random Forest model...\n",
      "Random Forest - Best Hyperparameters: {'max_depth': None, 'n_estimators': 150}\n"
     ]
    }
   ],
   "source": [
    "for model_name, model_class in [\n",
    "    ('Random Forest', RandomForestClassifier),\n",
    "]:\n",
    "    print(f'Optimizing {model_name} model...')\n",
    "    model = model_class()\n",
    "    grid_search = GridSearchCV(model, param_grid=param_grids[model_name], cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42), scoring=['accuracy', 'f1_weighted'], refit='accuracy')\n",
    "    grid_search.fit(X_tfidf, df['emotion'])\n",
    "\n",
    "    #print(f'{model_name} - Best Accuracy: {grid_search.best_score_[\"accuracy\"]:.2f}')\n",
    "    #print(f'{model_name} - Best F1-score: {grid_search.best_score_[\"f1_weighted\"]:.2f}')\n",
    "    print(f'{model_name} - Best Hyperparameters: {grid_search.best_params_}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T20:25:46.105514600Z",
     "start_time": "2024-06-05T20:23:04.349090400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: 0.59\n",
      "Average F1-score: 0.58\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "model = RandomForestClassifier(n_estimators=150, max_depth=None)\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracy_scores = []\n",
    "f1_scores = []\n",
    "\n",
    "for train_index, test_index in skf.split(X_tfidf, df['emotion']):\n",
    "    X_train_tfidf, X_test_tfidf = X_tfidf[train_index], X_tfidf[test_index]\n",
    "    y_train, y_test = df['emotion'].iloc[train_index], df['emotion'].iloc[test_index]\n",
    "\n",
    "    model.fit(X_train_tfidf, y_train)\n",
    "    y_pred = model.predict(X_test_tfidf)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "    accuracy_scores.append(accuracy)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "print(f'Average Accuracy: {sum(accuracy_scores) / len(accuracy_scores):.2f}')\n",
    "print(f'Average F1-score: {sum(f1_scores) / len(f1_scores):.2f}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T20:27:22.660111400Z",
     "start_time": "2024-06-05T20:26:23.228774400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "param_grids = {\n",
    "    'AdaBoost': {'n_estimators': [50, 100, 150], 'learning_rate': [0.1, 0.5, 1.0]},\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T20:27:57.457238200Z",
     "start_time": "2024-06-05T20:27:57.456725500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing AdaBoost model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost - Best Hyperparameters: {'learning_rate': 1.0, 'n_estimators': 50}\n"
     ]
    }
   ],
   "source": [
    "for model_name, model_class in [\n",
    "    ('AdaBoost', AdaBoostClassifier),\n",
    "]:\n",
    "    print(f'Optimizing {model_name} model...')\n",
    "    model = model_class()\n",
    "    grid_search = GridSearchCV(model, param_grid=param_grids[model_name], cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42), scoring=['accuracy', 'f1_weighted'], refit='accuracy')\n",
    "    grid_search.fit(X_tfidf, df['emotion'])\n",
    "\n",
    "    #print(f'{model_name} - Best Accuracy: {grid_search.best_score_[\"accuracy\"]:.2f}')\n",
    "    #print(f'{model_name} - Best F1-score: {grid_search.best_score_[\"f1_weighted\"]:.2f}')\n",
    "    print(f'{model_name} - Best Hyperparameters: {grid_search.best_params_}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T20:31:55.405547200Z",
     "start_time": "2024-06-05T20:28:00.185660700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: 0.47\n",
      "Average F1-score: 0.45\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "model = AdaBoostClassifier(n_estimators=50, learning_rate=1.0)\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracy_scores = []\n",
    "f1_scores = []\n",
    "\n",
    "for train_index, test_index in skf.split(X_tfidf, df['emotion']):\n",
    "    X_train_tfidf, X_test_tfidf = X_tfidf[train_index], X_tfidf[test_index]\n",
    "    y_train, y_test = df['emotion'].iloc[train_index], df['emotion'].iloc[test_index]\n",
    "\n",
    "    model.fit(X_train_tfidf, y_train)\n",
    "    y_pred = model.predict(X_test_tfidf)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "    accuracy_scores.append(accuracy)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "print(f'Average Accuracy: {sum(accuracy_scores) / len(accuracy_scores):.2f}')\n",
    "print(f'Average F1-score: {sum(f1_scores) / len(f1_scores):.2f}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T20:32:48.358944400Z",
     "start_time": "2024-06-05T20:32:35.358685100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [
    "param_grids = {\n",
    "    'Extra Tree': {'n_estimators': [50, 100, 150], 'criterion': ['gini', 'entropy']},\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T20:33:08.054742900Z",
     "start_time": "2024-06-05T20:33:08.054227200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing Extra Tree model...\n",
      "Extra Tree - Best Hyperparameters: {'criterion': 'entropy', 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "for model_name, model_class in [\n",
    "    ('Extra Tree', ExtraTreesClassifier),\n",
    "]:\n",
    "    print(f'Optimizing {model_name} model...')\n",
    "    model = model_class()\n",
    "    grid_search = GridSearchCV(model, param_grid=param_grids[model_name], cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42), scoring=['accuracy', 'f1_weighted'], refit='accuracy')\n",
    "    grid_search.fit(X_tfidf, df['emotion'])\n",
    "\n",
    "    #print(f'{model_name} - Best Accuracy: {grid_search.best_score_[\"accuracy\"]:.2f}')\n",
    "    #print(f'{model_name} - Best F1-score: {grid_search.best_score_[\"f1_weighted\"]:.2f}')\n",
    "    print(f'{model_name} - Best Hyperparameters: {grid_search.best_params_}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T20:40:08.952990900Z",
     "start_time": "2024-06-05T20:33:09.108768200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: 0.60\n",
      "Average F1-score: 0.59\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "model = ExtraTreesClassifier(criterion='entropy', n_estimators=100)\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracy_scores = []\n",
    "f1_scores = []\n",
    "\n",
    "for train_index, test_index in skf.split(X_tfidf, df['emotion']):\n",
    "    X_train_tfidf, X_test_tfidf = X_tfidf[train_index], X_tfidf[test_index]\n",
    "    y_train, y_test = df['emotion'].iloc[train_index], df['emotion'].iloc[test_index]\n",
    "\n",
    "    model.fit(X_train_tfidf, y_train)\n",
    "    y_pred = model.predict(X_test_tfidf)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "    accuracy_scores.append(accuracy)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "print(f'Average Accuracy: {sum(accuracy_scores) / len(accuracy_scores):.2f}')\n",
    "print(f'Average F1-score: {sum(f1_scores) / len(f1_scores):.2f}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T20:41:58.069584800Z",
     "start_time": "2024-06-05T20:40:48.969605200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [],
   "source": [
    "param_grids = {\n",
    "    'LightGBM': {'num_leaves': [31, 63, 127], 'learning_rate': [0.1, 0.2, 0.3]}\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T20:41:58.072630200Z",
     "start_time": "2024-06-05T20:41:58.069584800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing LightGBM model...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002810 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7474\n",
      "[LightGBM] [Info] Number of data points in the train set: 3939, number of used features: 317\n",
      "[LightGBM] [Info] Start training from score -1.582883\n",
      "[LightGBM] [Info] Start training from score -2.665554\n",
      "[LightGBM] [Info] Start training from score -1.213923\n",
      "[LightGBM] [Info] Start training from score -1.360977\n",
      "[LightGBM] [Info] Start training from score -1.762489\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002375 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7514\n",
      "[LightGBM] [Info] Number of data points in the train set: 3939, number of used features: 318\n",
      "[LightGBM] [Info] Start training from score -1.582883\n",
      "[LightGBM] [Info] Start training from score -2.665554\n",
      "[LightGBM] [Info] Start training from score -1.213923\n",
      "[LightGBM] [Info] Start training from score -1.360977\n",
      "[LightGBM] [Info] Start training from score -1.762489\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002449 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7439\n",
      "[LightGBM] [Info] Number of data points in the train set: 3939, number of used features: 315\n",
      "[LightGBM] [Info] Start training from score -1.581648\n",
      "[LightGBM] [Info] Start training from score -2.669210\n",
      "[LightGBM] [Info] Start training from score -1.213923\n",
      "[LightGBM] [Info] Start training from score -1.360977\n",
      "[LightGBM] [Info] Start training from score -1.762489\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002388 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7437\n",
      "[LightGBM] [Info] Number of data points in the train set: 3939, number of used features: 317\n",
      "[LightGBM] [Info] Start training from score -1.581648\n",
      "[LightGBM] [Info] Start training from score -2.669210\n",
      "[LightGBM] [Info] Start training from score -1.214778\n",
      "[LightGBM] [Info] Start training from score -1.359987\n",
      "[LightGBM] [Info] Start training from score -1.762489\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002532 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7410\n",
      "[LightGBM] [Info] Number of data points in the train set: 3940, number of used features: 309\n",
      "[LightGBM] [Info] Start training from score -1.581902\n",
      "[LightGBM] [Info] Start training from score -2.665808\n",
      "[LightGBM] [Info] Start training from score -1.215032\n",
      "[LightGBM] [Info] Start training from score -1.360241\n",
      "[LightGBM] [Info] Start training from score -1.762743\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002475 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7474\n",
      "[LightGBM] [Info] Number of data points in the train set: 3939, number of used features: 317\n",
      "[LightGBM] [Info] Start training from score -1.582883\n",
      "[LightGBM] [Info] Start training from score -2.665554\n",
      "[LightGBM] [Info] Start training from score -1.213923\n",
      "[LightGBM] [Info] Start training from score -1.360977\n",
      "[LightGBM] [Info] Start training from score -1.762489\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002451 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7514\n",
      "[LightGBM] [Info] Number of data points in the train set: 3939, number of used features: 318\n",
      "[LightGBM] [Info] Start training from score -1.582883\n",
      "[LightGBM] [Info] Start training from score -2.665554\n",
      "[LightGBM] [Info] Start training from score -1.213923\n",
      "[LightGBM] [Info] Start training from score -1.360977\n",
      "[LightGBM] [Info] Start training from score -1.762489\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002388 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7439\n",
      "[LightGBM] [Info] Number of data points in the train set: 3939, number of used features: 315\n",
      "[LightGBM] [Info] Start training from score -1.581648\n",
      "[LightGBM] [Info] Start training from score -2.669210\n",
      "[LightGBM] [Info] Start training from score -1.213923\n",
      "[LightGBM] [Info] Start training from score -1.360977\n",
      "[LightGBM] [Info] Start training from score -1.762489\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002536 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7437\n",
      "[LightGBM] [Info] Number of data points in the train set: 3939, number of used features: 317\n",
      "[LightGBM] [Info] Start training from score -1.581648\n",
      "[LightGBM] [Info] Start training from score -2.669210\n",
      "[LightGBM] [Info] Start training from score -1.214778\n",
      "[LightGBM] [Info] Start training from score -1.359987\n",
      "[LightGBM] [Info] Start training from score -1.762489\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003158 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7410\n",
      "[LightGBM] [Info] Number of data points in the train set: 3940, number of used features: 309\n",
      "[LightGBM] [Info] Start training from score -1.581902\n",
      "[LightGBM] [Info] Start training from score -2.665808\n",
      "[LightGBM] [Info] Start training from score -1.215032\n",
      "[LightGBM] [Info] Start training from score -1.360241\n",
      "[LightGBM] [Info] Start training from score -1.762743\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002640 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7474\n",
      "[LightGBM] [Info] Number of data points in the train set: 3939, number of used features: 317\n",
      "[LightGBM] [Info] Start training from score -1.582883\n",
      "[LightGBM] [Info] Start training from score -2.665554\n",
      "[LightGBM] [Info] Start training from score -1.213923\n",
      "[LightGBM] [Info] Start training from score -1.360977\n",
      "[LightGBM] [Info] Start training from score -1.762489\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002448 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7514\n",
      "[LightGBM] [Info] Number of data points in the train set: 3939, number of used features: 318\n",
      "[LightGBM] [Info] Start training from score -1.582883\n",
      "[LightGBM] [Info] Start training from score -2.665554\n",
      "[LightGBM] [Info] Start training from score -1.213923\n",
      "[LightGBM] [Info] Start training from score -1.360977\n",
      "[LightGBM] [Info] Start training from score -1.762489\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002573 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7439\n",
      "[LightGBM] [Info] Number of data points in the train set: 3939, number of used features: 315\n",
      "[LightGBM] [Info] Start training from score -1.581648\n",
      "[LightGBM] [Info] Start training from score -2.669210\n",
      "[LightGBM] [Info] Start training from score -1.213923\n",
      "[LightGBM] [Info] Start training from score -1.360977\n",
      "[LightGBM] [Info] Start training from score -1.762489\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001944 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7437\n",
      "[LightGBM] [Info] Number of data points in the train set: 3939, number of used features: 317\n",
      "[LightGBM] [Info] Start training from score -1.581648\n",
      "[LightGBM] [Info] Start training from score -2.669210\n",
      "[LightGBM] [Info] Start training from score -1.214778\n",
      "[LightGBM] [Info] Start training from score -1.359987\n",
      "[LightGBM] [Info] Start training from score -1.762489\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002748 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7410\n",
      "[LightGBM] [Info] Number of data points in the train set: 3940, number of used features: 309\n",
      "[LightGBM] [Info] Start training from score -1.581902\n",
      "[LightGBM] [Info] Start training from score -2.665808\n",
      "[LightGBM] [Info] Start training from score -1.215032\n",
      "[LightGBM] [Info] Start training from score -1.360241\n",
      "[LightGBM] [Info] Start training from score -1.762743\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002632 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7474\n",
      "[LightGBM] [Info] Number of data points in the train set: 3939, number of used features: 317\n",
      "[LightGBM] [Info] Start training from score -1.582883\n",
      "[LightGBM] [Info] Start training from score -2.665554\n",
      "[LightGBM] [Info] Start training from score -1.213923\n",
      "[LightGBM] [Info] Start training from score -1.360977\n",
      "[LightGBM] [Info] Start training from score -1.762489\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002182 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7514\n",
      "[LightGBM] [Info] Number of data points in the train set: 3939, number of used features: 318\n",
      "[LightGBM] [Info] Start training from score -1.582883\n",
      "[LightGBM] [Info] Start training from score -2.665554\n",
      "[LightGBM] [Info] Start training from score -1.213923\n",
      "[LightGBM] [Info] Start training from score -1.360977\n",
      "[LightGBM] [Info] Start training from score -1.762489\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002527 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7439\n",
      "[LightGBM] [Info] Number of data points in the train set: 3939, number of used features: 315\n",
      "[LightGBM] [Info] Start training from score -1.581648\n",
      "[LightGBM] [Info] Start training from score -2.669210\n",
      "[LightGBM] [Info] Start training from score -1.213923\n",
      "[LightGBM] [Info] Start training from score -1.360977\n",
      "[LightGBM] [Info] Start training from score -1.762489\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001479 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7437\n",
      "[LightGBM] [Info] Number of data points in the train set: 3939, number of used features: 317\n",
      "[LightGBM] [Info] Start training from score -1.581648\n",
      "[LightGBM] [Info] Start training from score -2.669210\n",
      "[LightGBM] [Info] Start training from score -1.214778\n",
      "[LightGBM] [Info] Start training from score -1.359987\n",
      "[LightGBM] [Info] Start training from score -1.762489\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002354 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7410\n",
      "[LightGBM] [Info] Number of data points in the train set: 3940, number of used features: 309\n",
      "[LightGBM] [Info] Start training from score -1.581902\n",
      "[LightGBM] [Info] Start training from score -2.665808\n",
      "[LightGBM] [Info] Start training from score -1.215032\n",
      "[LightGBM] [Info] Start training from score -1.360241\n",
      "[LightGBM] [Info] Start training from score -1.762743\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002808 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7474\n",
      "[LightGBM] [Info] Number of data points in the train set: 3939, number of used features: 317\n",
      "[LightGBM] [Info] Start training from score -1.582883\n",
      "[LightGBM] [Info] Start training from score -2.665554\n",
      "[LightGBM] [Info] Start training from score -1.213923\n",
      "[LightGBM] [Info] Start training from score -1.360977\n",
      "[LightGBM] [Info] Start training from score -1.762489\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002836 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7514\n",
      "[LightGBM] [Info] Number of data points in the train set: 3939, number of used features: 318\n",
      "[LightGBM] [Info] Start training from score -1.582883\n",
      "[LightGBM] [Info] Start training from score -2.665554\n",
      "[LightGBM] [Info] Start training from score -1.213923\n",
      "[LightGBM] [Info] Start training from score -1.360977\n",
      "[LightGBM] [Info] Start training from score -1.762489\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002578 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7439\n",
      "[LightGBM] [Info] Number of data points in the train set: 3939, number of used features: 315\n",
      "[LightGBM] [Info] Start training from score -1.581648\n",
      "[LightGBM] [Info] Start training from score -2.669210\n",
      "[LightGBM] [Info] Start training from score -1.213923\n",
      "[LightGBM] [Info] Start training from score -1.360977\n",
      "[LightGBM] [Info] Start training from score -1.762489\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002537 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7437\n",
      "[LightGBM] [Info] Number of data points in the train set: 3939, number of used features: 317\n",
      "[LightGBM] [Info] Start training from score -1.581648\n",
      "[LightGBM] [Info] Start training from score -2.669210\n",
      "[LightGBM] [Info] Start training from score -1.214778\n",
      "[LightGBM] [Info] Start training from score -1.359987\n",
      "[LightGBM] [Info] Start training from score -1.762489\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002397 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7410\n",
      "[LightGBM] [Info] Number of data points in the train set: 3940, number of used features: 309\n",
      "[LightGBM] [Info] Start training from score -1.581902\n",
      "[LightGBM] [Info] Start training from score -2.665808\n",
      "[LightGBM] [Info] Start training from score -1.215032\n",
      "[LightGBM] [Info] Start training from score -1.360241\n",
      "[LightGBM] [Info] Start training from score -1.762743\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002479 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7474\n",
      "[LightGBM] [Info] Number of data points in the train set: 3939, number of used features: 317\n",
      "[LightGBM] [Info] Start training from score -1.582883\n",
      "[LightGBM] [Info] Start training from score -2.665554\n",
      "[LightGBM] [Info] Start training from score -1.213923\n",
      "[LightGBM] [Info] Start training from score -1.360977\n",
      "[LightGBM] [Info] Start training from score -1.762489\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001695 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7514\n",
      "[LightGBM] [Info] Number of data points in the train set: 3939, number of used features: 318\n",
      "[LightGBM] [Info] Start training from score -1.582883\n",
      "[LightGBM] [Info] Start training from score -2.665554\n",
      "[LightGBM] [Info] Start training from score -1.213923\n",
      "[LightGBM] [Info] Start training from score -1.360977\n",
      "[LightGBM] [Info] Start training from score -1.762489\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002347 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7439\n",
      "[LightGBM] [Info] Number of data points in the train set: 3939, number of used features: 315\n",
      "[LightGBM] [Info] Start training from score -1.581648\n",
      "[LightGBM] [Info] Start training from score -2.669210\n",
      "[LightGBM] [Info] Start training from score -1.213923\n",
      "[LightGBM] [Info] Start training from score -1.360977\n",
      "[LightGBM] [Info] Start training from score -1.762489\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001533 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7437\n",
      "[LightGBM] [Info] Number of data points in the train set: 3939, number of used features: 317\n",
      "[LightGBM] [Info] Start training from score -1.581648\n",
      "[LightGBM] [Info] Start training from score -2.669210\n",
      "[LightGBM] [Info] Start training from score -1.214778\n",
      "[LightGBM] [Info] Start training from score -1.359987\n",
      "[LightGBM] [Info] Start training from score -1.762489\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002685 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7410\n",
      "[LightGBM] [Info] Number of data points in the train set: 3940, number of used features: 309\n",
      "[LightGBM] [Info] Start training from score -1.581902\n",
      "[LightGBM] [Info] Start training from score -2.665808\n",
      "[LightGBM] [Info] Start training from score -1.215032\n",
      "[LightGBM] [Info] Start training from score -1.360241\n",
      "[LightGBM] [Info] Start training from score -1.762743\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002481 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7474\n",
      "[LightGBM] [Info] Number of data points in the train set: 3939, number of used features: 317\n",
      "[LightGBM] [Info] Start training from score -1.582883\n",
      "[LightGBM] [Info] Start training from score -2.665554\n",
      "[LightGBM] [Info] Start training from score -1.213923\n",
      "[LightGBM] [Info] Start training from score -1.360977\n",
      "[LightGBM] [Info] Start training from score -1.762489\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007657 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7514\n",
      "[LightGBM] [Info] Number of data points in the train set: 3939, number of used features: 318\n",
      "[LightGBM] [Info] Start training from score -1.582883\n",
      "[LightGBM] [Info] Start training from score -2.665554\n",
      "[LightGBM] [Info] Start training from score -1.213923\n",
      "[LightGBM] [Info] Start training from score -1.360977\n",
      "[LightGBM] [Info] Start training from score -1.762489\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002458 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7439\n",
      "[LightGBM] [Info] Number of data points in the train set: 3939, number of used features: 315\n",
      "[LightGBM] [Info] Start training from score -1.581648\n",
      "[LightGBM] [Info] Start training from score -2.669210\n",
      "[LightGBM] [Info] Start training from score -1.213923\n",
      "[LightGBM] [Info] Start training from score -1.360977\n",
      "[LightGBM] [Info] Start training from score -1.762489\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002514 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7437\n",
      "[LightGBM] [Info] Number of data points in the train set: 3939, number of used features: 317\n",
      "[LightGBM] [Info] Start training from score -1.581648\n",
      "[LightGBM] [Info] Start training from score -2.669210\n",
      "[LightGBM] [Info] Start training from score -1.214778\n",
      "[LightGBM] [Info] Start training from score -1.359987\n",
      "[LightGBM] [Info] Start training from score -1.762489\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002393 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7410\n",
      "[LightGBM] [Info] Number of data points in the train set: 3940, number of used features: 309\n",
      "[LightGBM] [Info] Start training from score -1.581902\n",
      "[LightGBM] [Info] Start training from score -2.665808\n",
      "[LightGBM] [Info] Start training from score -1.215032\n",
      "[LightGBM] [Info] Start training from score -1.360241\n",
      "[LightGBM] [Info] Start training from score -1.762743\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002458 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7474\n",
      "[LightGBM] [Info] Number of data points in the train set: 3939, number of used features: 317\n",
      "[LightGBM] [Info] Start training from score -1.582883\n",
      "[LightGBM] [Info] Start training from score -2.665554\n",
      "[LightGBM] [Info] Start training from score -1.213923\n",
      "[LightGBM] [Info] Start training from score -1.360977\n",
      "[LightGBM] [Info] Start training from score -1.762489\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002421 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7514\n",
      "[LightGBM] [Info] Number of data points in the train set: 3939, number of used features: 318\n",
      "[LightGBM] [Info] Start training from score -1.582883\n",
      "[LightGBM] [Info] Start training from score -2.665554\n",
      "[LightGBM] [Info] Start training from score -1.213923\n",
      "[LightGBM] [Info] Start training from score -1.360977\n",
      "[LightGBM] [Info] Start training from score -1.762489\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001525 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7439\n",
      "[LightGBM] [Info] Number of data points in the train set: 3939, number of used features: 315\n",
      "[LightGBM] [Info] Start training from score -1.581648\n",
      "[LightGBM] [Info] Start training from score -2.669210\n",
      "[LightGBM] [Info] Start training from score -1.213923\n",
      "[LightGBM] [Info] Start training from score -1.360977\n",
      "[LightGBM] [Info] Start training from score -1.762489\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002729 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7437\n",
      "[LightGBM] [Info] Number of data points in the train set: 3939, number of used features: 317\n",
      "[LightGBM] [Info] Start training from score -1.581648\n",
      "[LightGBM] [Info] Start training from score -2.669210\n",
      "[LightGBM] [Info] Start training from score -1.214778\n",
      "[LightGBM] [Info] Start training from score -1.359987\n",
      "[LightGBM] [Info] Start training from score -1.762489\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001484 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7410\n",
      "[LightGBM] [Info] Number of data points in the train set: 3940, number of used features: 309\n",
      "[LightGBM] [Info] Start training from score -1.581902\n",
      "[LightGBM] [Info] Start training from score -2.665808\n",
      "[LightGBM] [Info] Start training from score -1.215032\n",
      "[LightGBM] [Info] Start training from score -1.360241\n",
      "[LightGBM] [Info] Start training from score -1.762743\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002507 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7474\n",
      "[LightGBM] [Info] Number of data points in the train set: 3939, number of used features: 317\n",
      "[LightGBM] [Info] Start training from score -1.582883\n",
      "[LightGBM] [Info] Start training from score -2.665554\n",
      "[LightGBM] [Info] Start training from score -1.213923\n",
      "[LightGBM] [Info] Start training from score -1.360977\n",
      "[LightGBM] [Info] Start training from score -1.762489\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002455 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7514\n",
      "[LightGBM] [Info] Number of data points in the train set: 3939, number of used features: 318\n",
      "[LightGBM] [Info] Start training from score -1.582883\n",
      "[LightGBM] [Info] Start training from score -2.665554\n",
      "[LightGBM] [Info] Start training from score -1.213923\n",
      "[LightGBM] [Info] Start training from score -1.360977\n",
      "[LightGBM] [Info] Start training from score -1.762489\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002616 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7439\n",
      "[LightGBM] [Info] Number of data points in the train set: 3939, number of used features: 315\n",
      "[LightGBM] [Info] Start training from score -1.581648\n",
      "[LightGBM] [Info] Start training from score -2.669210\n",
      "[LightGBM] [Info] Start training from score -1.213923\n",
      "[LightGBM] [Info] Start training from score -1.360977\n",
      "[LightGBM] [Info] Start training from score -1.762489\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002429 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7437\n",
      "[LightGBM] [Info] Number of data points in the train set: 3939, number of used features: 317\n",
      "[LightGBM] [Info] Start training from score -1.581648\n",
      "[LightGBM] [Info] Start training from score -2.669210\n",
      "[LightGBM] [Info] Start training from score -1.214778\n",
      "[LightGBM] [Info] Start training from score -1.359987\n",
      "[LightGBM] [Info] Start training from score -1.762489\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002425 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7410\n",
      "[LightGBM] [Info] Number of data points in the train set: 3940, number of used features: 309\n",
      "[LightGBM] [Info] Start training from score -1.581902\n",
      "[LightGBM] [Info] Start training from score -2.665808\n",
      "[LightGBM] [Info] Start training from score -1.215032\n",
      "[LightGBM] [Info] Start training from score -1.360241\n",
      "[LightGBM] [Info] Start training from score -1.762743\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003873 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9722\n",
      "[LightGBM] [Info] Number of data points in the train set: 4924, number of used features: 388\n",
      "[LightGBM] [Info] Start training from score -1.582193\n",
      "[LightGBM] [Info] Start training from score -2.667066\n",
      "[LightGBM] [Info] Start training from score -1.214316\n",
      "[LightGBM] [Info] Start training from score -1.360631\n",
      "[LightGBM] [Info] Start training from score -1.762540\n",
      "LightGBM - Best Hyperparameters: {'learning_rate': 0.1, 'num_leaves': 31}\n"
     ]
    }
   ],
   "source": [
    "for model_name, model_class in [\n",
    "    ('LightGBM', LGBMClassifier)\n",
    "]:\n",
    "    print(f'Optimizing {model_name} model...')\n",
    "    model = model_class()\n",
    "    grid_search = GridSearchCV(model, param_grid=param_grids[model_name], cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42), scoring=['accuracy', 'f1_weighted'], refit='accuracy')\n",
    "    grid_search.fit(X_tfidf, df['emotion'])\n",
    "\n",
    "    #print(f'{model_name} - Best Accuracy: {grid_search.best_score_[\"accuracy\"]:.2f}')\n",
    "    #print(f'{model_name} - Best F1-score: {grid_search.best_score_[\"f1_weighted\"]:.2f}')\n",
    "    print(f'{model_name} - Best Hyperparameters: {grid_search.best_params_}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T20:43:21.342671500Z",
     "start_time": "2024-06-05T20:42:14.607057100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002554 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7474\n",
      "[LightGBM] [Info] Number of data points in the train set: 3939, number of used features: 317\n",
      "[LightGBM] [Info] Start training from score -1.582883\n",
      "[LightGBM] [Info] Start training from score -2.665554\n",
      "[LightGBM] [Info] Start training from score -1.213923\n",
      "[LightGBM] [Info] Start training from score -1.360977\n",
      "[LightGBM] [Info] Start training from score -1.762489\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001742 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7514\n",
      "[LightGBM] [Info] Number of data points in the train set: 3939, number of used features: 318\n",
      "[LightGBM] [Info] Start training from score -1.582883\n",
      "[LightGBM] [Info] Start training from score -2.665554\n",
      "[LightGBM] [Info] Start training from score -1.213923\n",
      "[LightGBM] [Info] Start training from score -1.360977\n",
      "[LightGBM] [Info] Start training from score -1.762489\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002364 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7439\n",
      "[LightGBM] [Info] Number of data points in the train set: 3939, number of used features: 315\n",
      "[LightGBM] [Info] Start training from score -1.581648\n",
      "[LightGBM] [Info] Start training from score -2.669210\n",
      "[LightGBM] [Info] Start training from score -1.213923\n",
      "[LightGBM] [Info] Start training from score -1.360977\n",
      "[LightGBM] [Info] Start training from score -1.762489\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002366 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7437\n",
      "[LightGBM] [Info] Number of data points in the train set: 3939, number of used features: 317\n",
      "[LightGBM] [Info] Start training from score -1.581648\n",
      "[LightGBM] [Info] Start training from score -2.669210\n",
      "[LightGBM] [Info] Start training from score -1.214778\n",
      "[LightGBM] [Info] Start training from score -1.359987\n",
      "[LightGBM] [Info] Start training from score -1.762489\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002264 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7410\n",
      "[LightGBM] [Info] Number of data points in the train set: 3940, number of used features: 309\n",
      "[LightGBM] [Info] Start training from score -1.581902\n",
      "[LightGBM] [Info] Start training from score -2.665808\n",
      "[LightGBM] [Info] Start training from score -1.215032\n",
      "[LightGBM] [Info] Start training from score -1.360241\n",
      "[LightGBM] [Info] Start training from score -1.762743\n",
      "Average Accuracy: 0.56\n",
      "Average F1-score: 0.56\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "model = LGBMClassifier(learning_rate=0.1, num_leaves=31)\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracy_scores = []\n",
    "f1_scores = []\n",
    "\n",
    "for train_index, test_index in skf.split(X_tfidf, df['emotion']):\n",
    "    X_train_tfidf, X_test_tfidf = X_tfidf[train_index], X_tfidf[test_index]\n",
    "    y_train, y_test = df['emotion'].iloc[train_index], df['emotion'].iloc[test_index]\n",
    "\n",
    "    model.fit(X_train_tfidf, y_train)\n",
    "    y_pred = model.predict(X_test_tfidf)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "    accuracy_scores.append(accuracy)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "print(f'Average Accuracy: {sum(accuracy_scores) / len(accuracy_scores):.2f}')\n",
    "print(f'Average F1-score: {sum(f1_scores) / len(f1_scores):.2f}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T20:44:24.110630200Z",
     "start_time": "2024-06-05T20:44:20.419308400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [],
   "source": [
    "param_grids = {\n",
    "    'XGBoost': {'max_depth': [3, 5, 7], 'learning_rate': [0.1, 0.2, 0.3]},\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T20:44:31.727360700Z",
     "start_time": "2024-06-05T20:44:31.719841Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing XGBoost model...\n",
      "XGBoost - Best Hyperparameters: {'learning_rate': 0.3, 'max_depth': 5}\n"
     ]
    }
   ],
   "source": [
    "for model_name, model_class in [\n",
    "    ('XGBoost', XGBClassifier),\n",
    "]:\n",
    "    print(f'Optimizing {model_name} model...')\n",
    "    model = model_class()\n",
    "    grid_search = GridSearchCV(model, param_grid=param_grids[model_name], cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42), scoring=['accuracy', 'f1_weighted'], refit='accuracy')\n",
    "    grid_search.fit(X_tfidf, df['emotion'])\n",
    "\n",
    "    #print(f'{model_name} - Best Accuracy: {grid_search.best_score_[\"accuracy\"]:.2f}')\n",
    "    #print(f'{model_name} - Best F1-score: {grid_search.best_score_[\"f1_weighted\"]:.2f}')\n",
    "    print(f'{model_name} - Best Hyperparameters: {grid_search.best_params_}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T20:45:42.160682600Z",
     "start_time": "2024-06-05T20:44:32.260504700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: 0.60\n",
      "Average F1-score: 0.60\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "model = XGBClassifier(learning_rate=0.3, max_depth=5)\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracy_scores = []\n",
    "f1_scores = []\n",
    "\n",
    "for train_index, test_index in skf.split(X_tfidf, df['emotion']):\n",
    "    X_train_tfidf, X_test_tfidf = X_tfidf[train_index], X_tfidf[test_index]\n",
    "    y_train, y_test = df['emotion'].iloc[train_index], df['emotion'].iloc[test_index]\n",
    "\n",
    "    model.fit(X_train_tfidf, y_train)\n",
    "    y_pred = model.predict(X_test_tfidf)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "    accuracy_scores.append(accuracy)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "print(f'Average Accuracy: {sum(accuracy_scores) / len(accuracy_scores):.2f}')\n",
    "print(f'Average F1-score: {sum(f1_scores) / len(f1_scores):.2f}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T20:46:16.260129500Z",
     "start_time": "2024-06-05T20:46:09.973771400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "param_grids = {\n",
    "    'Gradient Boosting': {'n_estimators': [50, 100, 150], 'learning_rate': [0.1, 0.2, 0.3]},\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T19:52:30.369719400Z",
     "start_time": "2024-06-05T19:52:30.368523600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing Gradient Boosting model...\n",
      "Gradient Boosting - Best Hyperparameters: {'learning_rate': 0.1, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "for model_name, model_class in [\n",
    "    ('Gradient Boosting', GradientBoostingClassifier),\n",
    "]:\n",
    "    print(f'Optimizing {model_name} model...')\n",
    "    model = model_class()\n",
    "    grid_search = GridSearchCV(model, param_grid=param_grids[model_name], cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42), scoring=['accuracy', 'f1_weighted'], refit='accuracy')\n",
    "    grid_search.fit(X_tfidf, df['emotion'])\n",
    "\n",
    "    #print(f'{model_name} - Best Accuracy: {grid_search.best_score_[\"accuracy\"]:.2f}')\n",
    "    #print(f'{model_name} - Best F1-score: {grid_search.best_score_[\"f1_weighted\"]:.2f}')\n",
    "    print(f'{model_name} - Best Hyperparameters: {grid_search.best_params_}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T20:06:32.840713900Z",
     "start_time": "2024-06-05T19:52:46.278755100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: 0.58\n",
      "Average F1-score: 0.58\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "model = GradientBoostingClassifier(learning_rate=0.1, n_estimators=100)\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracy_scores = []\n",
    "f1_scores = []\n",
    "\n",
    "for train_index, test_index in skf.split(X_tfidf, df['emotion']):\n",
    "    X_train_tfidf, X_test_tfidf = X_tfidf[train_index], X_tfidf[test_index]\n",
    "    y_train, y_test = df['emotion'].iloc[train_index], df['emotion'].iloc[test_index]\n",
    "\n",
    "    model.fit(X_train_tfidf, y_train)\n",
    "    y_pred = model.predict(X_test_tfidf)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "    accuracy_scores.append(accuracy)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "print(f'Average Accuracy: {sum(accuracy_scores) / len(accuracy_scores):.2f}')\n",
    "print(f'Average F1-score: {sum(f1_scores) / len(f1_scores):.2f}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T20:49:07.668130500Z",
     "start_time": "2024-06-05T20:46:20.677552500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: 0.61\n",
      "Average F1-score: 0.61\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracy_scores = []\n",
    "f1_scores = []\n",
    "\n",
    "for train_index, test_index in skf.split(X_tfidf, df['emotion']):\n",
    "    X_train_tfidf, X_test_tfidf = X_tfidf[train_index], X_tfidf[test_index]\n",
    "    y_train, y_test = df['emotion'].iloc[train_index], df['emotion'].iloc[test_index]\n",
    "\n",
    "    model.fit(X_train_tfidf, y_train)\n",
    "    y_pred = model.predict(X_test_tfidf)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "    accuracy_scores.append(accuracy)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "print(f'Average Accuracy: {sum(accuracy_scores) / len(accuracy_scores):.2f}')\n",
    "print(f'Average F1-score: {sum(f1_scores) / len(f1_scores):.2f}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T20:49:26.433577700Z",
     "start_time": "2024-06-05T20:49:23.796441800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: 0.54\n",
      "Average F1-score: 0.53\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "model = KNeighborsClassifier()\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracy_scores = []\n",
    "f1_scores = []\n",
    "\n",
    "for train_index, test_index in skf.split(X_tfidf, df['emotion']):\n",
    "    X_train_tfidf, X_test_tfidf = X_tfidf[train_index], X_tfidf[test_index]\n",
    "    y_train, y_test = df['emotion'].iloc[train_index], df['emotion'].iloc[test_index]\n",
    "\n",
    "    model.fit(X_train_tfidf, y_train)\n",
    "    y_pred = model.predict(X_test_tfidf)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "    accuracy_scores.append(accuracy)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "print(f'Average Accuracy: {sum(accuracy_scores) / len(accuracy_scores):.2f}')\n",
    "print(f'Average F1-score: {sum(f1_scores) / len(f1_scores):.2f}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T20:49:28.209014300Z",
     "start_time": "2024-06-05T20:49:27.814631100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
